{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T22:23:07.574301Z",
     "start_time": "2025-01-06T22:23:07.559971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "from utils import read_json, get_data, save_json"
   ],
   "id": "5b3f74b0f16cef6d",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_data' from 'utils' (/sshfs/lingbao/ecnu_essay/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m read_json, get_data, save_json\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'get_data' from 'utils' (/sshfs/lingbao/ecnu_essay/utils.py)"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T18:27:51.409984Z",
     "start_time": "2025-01-15T18:27:51.315119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import opencc\n",
    "\n",
    "from utils import read_json, get_data\n",
    "\n",
    "# 创建转换器对象，'t2s' 表示从繁体到简体\n",
    "converter = opencc.OpenCC('s2t.json')\n",
    "\n",
    "# 繁体文本\n",
    "traditional_text = \"\"\"請判斷输入句子中是否存在語法錯誤。\n",
    "\n",
    "如果存在错误，標註錯誤類型并给出修正後文字（错误类型包括：缺字漏字、錯別字錯誤、缺少標點、錯用標點、主語不明、謂語殘缺、賓語殘缺、其他成分殘缺、主語多餘、虛詞多餘、其他成分多餘、動賓搭配不當、語序不當、其他搭配不當）；如果不存在错误，直接标注为「无错误」。\n",
    "\n",
    "输出格式为「標註結果：<标注结果>\\\\n修正後文字（如果有错误）：<修正後文字>」。\n",
    "\n",
    "样例1：输入「昨天，來賓到我校參觀，老師讓我當小導遊，我感到十分緊張。」，输出「標註結果：無錯誤\"」。\n",
    "\n",
    "样例2：输入「她把一張有一個正方形的紙放進打印機裏，打印機開始印刷了，然後，「唔」一聲打印機印出來了。」，输出「標註結果：虛詞多餘、主詞不明\\\\n修正後文字：她把一張正方形的紙放進打印機裏，打印機開始印刷了，然後，打印機「唔」得一聲，紙被印出來了。\"」\"\"\"\n",
    "# traditional_text = \"回憶著我的初中時光\"\n",
    "\n",
    "# 转换为简体\n",
    "simplified_text = converter.convert(traditional_text)\n",
    "\n",
    "print(simplified_text)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請判斷輸入句子中是否存在語法錯誤。\n",
      "\n",
      "如果存在錯誤，標註錯誤類型並給出修正後文字（錯誤類型包括：缺字漏字、錯別字錯誤、缺少標點、錯用標點、主語不明、謂語殘缺、賓語殘缺、其他成分殘缺、主語多餘、虛詞多餘、其他成分多餘、動賓搭配不當、語序不當、其他搭配不當）；如果不存在錯誤，直接標註爲「無錯誤」。\n",
      "\n",
      "輸出格式爲「標註結果：<標註結果>\\n修正後文字（如果有錯誤）：<修正後文字>」。\n",
      "\n",
      "樣例1：輸入「昨天，來賓到我校參觀，老師讓我當小導遊，我感到十分緊張。」，輸出「標註結果：無錯誤\"」。\n",
      "\n",
      "樣例2：輸入「她把一張有一個正方形的紙放進打印機裏，打印機開始印刷了，然後，「唔」一聲打印機印出來了。」，輸出「標註結果：虛詞多餘、主詞不明\\n修正後文字：她把一張正方形的紙放進打印機裏，打印機開始印刷了，然後，打印機「唔」得一聲，紙被印出來了。\"」\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T07:59:35.144250Z",
     "start_time": "2024-12-18T07:59:35.139860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def contains_traditional_chinese(text):\n",
    "    \"\"\"\n",
    "    判断给定的文本中是否包含繁体字\n",
    "    :param text: 输入的文本字符串\n",
    "    :return: 如果包含繁体字，返回 True；否则返回 False\n",
    "    \"\"\"\n",
    "    # 繁体字的 Unicode 范围通常在以下区域\n",
    "    traditional_chinese_range = re.compile(r'[\\u4e00-\\u9fff\\uff00-\\uffef]')\n",
    "    \n",
    "    # 使用 findall 找到所有匹配的字符\n",
    "    matches = traditional_chinese_range.findall(text)\n",
    "    if matches:\n",
    "        print(\"找到的繁体字字符:\", matches)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"没有找到繁体字\")\n",
    "        return False\n",
    "\n",
    "# 测试\n",
    "test_sentence = \"我還要感謝我的同學，回憶著我的初中時光\"\n",
    "print(contains_traditional_chinese(test_sentence))  # 输出 True\n",
    "\n",
    "test_sentence_2 = \"我还要感谢我的同学，回忆着我的初中时光\"\n",
    "print(contains_traditional_chinese(test_sentence_2))  # 输出 False"
   ],
   "id": "485ceb036f917394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到的繁体字字符: ['我', '還', '要', '感', '謝', '我', '的', '同', '學', '，', '回', '憶', '著', '我', '的', '初', '中', '時', '光']\n",
      "True\n",
      "找到的繁体字字符: ['我', '还', '要', '感', '谢', '我', '的', '同', '学', '，', '回', '忆', '着', '我', '的', '初', '中', '时', '光']\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if text != convert_to_sc(text):\n",
    "\tprint(\"包含简体\")\n",
    "else:\n",
    "    print(\"不包含简体\")"
   ],
   "id": "14b6066376a20e5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T05:48:08.263770Z",
     "start_time": "2024-12-19T05:48:08.231220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "json_data = read_json(get_data('lijiang_sents_20241218.json'))\n",
    "print(len(json_data))"
   ],
   "id": "c5cd2c579ea1d9bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10050\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:14:47.361480Z",
     "start_time": "2024-12-24T11:14:46.860518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlxlm import load, generate\n",
    "\n",
    "model, tokenizer = load('Qwen/Qwen2.5-7B-Instruct-MLX', tokenizer_config={\"eos_token\": \"<|im_end|>\"})\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "response = generate(model, tokenizer, prompt=text, verbose=True, top_p=0.8, temp=0.7, repetition_penalty=1.05, max_tokens=512)"
   ],
   "id": "b4cbc13c6dfdf3c8",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxlm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlxlm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load, generate\n\u001B[1;32m      3\u001B[0m model, tokenizer \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQwen/Qwen2.5-7B-Instruct-MLX\u001B[39m\u001B[38;5;124m'\u001B[39m, tokenizer_config\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meos_token\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|im_end|>\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[1;32m      5\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGive me a short introduction to large language model.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'mlxlm'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:35:55.730090Z",
     "start_time": "2024-12-24T07:35:55.717725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    'HKVariants.txt',\n",
    "    'JPVariants.txt',\n",
    "    'STCharacters.txt',\n",
    "    'TSCharacters.txt',\n",
    "    'TWVariants.txt'\n",
    "]\n",
    "\n",
    "# 初始化一个空的 set\n",
    "all_first_column_set = set()\n",
    "\n",
    "# 遍历文件路径\n",
    "for file_path in file_paths:\n",
    "    with open(get_data(f'opencc_dictionary/{file_path}'), 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 每行按照制表符分割，获取第一列的字符\n",
    "            first_column = line.split('\\t')[0]\n",
    "            # 将第一列的字符添加到 set 中\n",
    "            all_first_column_set.add(first_column)\n",
    "\n",
    "# 输出结果\n",
    "output_file_path = get_data('datas/archives/my_st_chars.txt')\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    for char in all_first_column_set:\n",
    "        output_file.write(char + '\\n')\n",
    "\n",
    "print(f\"结果已保存到 {output_file_path}\")\n"
   ],
   "id": "97aafc3ec0e7508",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果已保存到 /Users/antler/Library/Mobile Documents/com~apple~CloudDocs/Area/Code/ecnu_essay/datas/my_st_chars.txt\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T12:20:06.939030Z",
     "start_time": "2024-12-25T12:20:06.818895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import get_data, read_json, save_json\n",
    "\n",
    "# 字符级错误\n",
    "char_level_errors = [\n",
    "    \"缺字漏字\",\n",
    "    \"错别字错误\",\n",
    "    \"缺少标点\",\n",
    "    \"错用标点\"\n",
    "]\n",
    "\n",
    "# 成分赘余型错误\n",
    "redundant_component_errors = [\n",
    "    \"主语多余\",\n",
    "    \"虚词多余\",\n",
    "    \"其他成分多余\"\n",
    "]\n",
    "\n",
    "# 成分残缺型错误\n",
    "missing_component_errors = [\n",
    "    \"主语不明\",\n",
    "    \"谓语残缺\",\n",
    "    \"宾语残缺\",\n",
    "    \"其他成分残缺\"\n",
    "]\n",
    "\n",
    "# 成分搭配不当型错误\n",
    "misaligned_component_errors = [\n",
    "    \"动宾搭配不当\",\n",
    "    \"语序不当\",\n",
    "    \"其他搭配不当\"\n",
    "]\n",
    "\n",
    "errors = char_level_errors + redundant_component_errors + missing_component_errors + misaligned_component_errors\n",
    "errors += ['无错误']\n"
   ],
   "id": "6462965f27ec7343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sshfs/lingbao/ecnu_essay/datas/temp/lijiang_sents_20241225.json saved with 300 samples!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T12:25:57.481941Z",
     "start_time": "2024-12-25T12:25:57.290062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sents = read_json(get_data('datas/archives/lijiang_sents_20250114.json'))\n",
    "category_count = {}\n",
    "for e in errors:\n",
    "    category_count[e] = 0\n",
    "num = 1\n",
    "for i in sents:\n",
    "    if i['count'] > 300:\n",
    "        break\n",
    "    for e in i['fine_grained_error_type']:\n",
    "        category_count[e] += 1\n",
    "save_json(category_count, get_data('temp/category_count.json'))"
   ],
   "id": "82f41c1c55f2535e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sshfs/lingbao/ecnu_essay/datas/temp/category_count.json saved with 15 samples!\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T18:29:29.734018Z",
     "start_time": "2025-01-15T18:29:29.726887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction = \"\"\"請判斷輸入句子中是否存在語法錯誤。\n",
    "\n",
    "如果存在錯誤，標註錯誤類型並給出修正後文字（錯誤類型包括：缺字漏字、錯別字錯誤、缺少標點、錯用標點、主語不明、謂語殘缺、賓語殘缺、其他成分殘缺、主語多餘、虛詞多餘、其他成分多餘、動賓搭配不當、語序不當、其他搭配不當）；如果不存在錯誤，直接標註爲「無錯誤」。\n",
    "\n",
    "輸出格式爲「標註結果：<標註結果>\\\\n修正後文字（如果有錯誤）：<修正後文字>」。\n",
    "\n",
    "樣例1：輸入「昨天，來賓到我校參觀，老師讓我當小導遊，我感到十分緊張。」，輸出「標註結果：無錯誤\"」。\n",
    "\n",
    "樣例2：輸入「她把一張有一個正方形的紙放進打印機裏，打印機開始印刷了，然後，「唔」一聲打印機印出來了。」，輸出「標註結果：虛詞多餘、主詞不明\\\\n修正後文字：她把一張正方形的紙放進打印機裏，打印機開始印刷了，然後，打印機「唔」得一聲，紙被印出來了。」\"\"\"\n",
    "print(instruction)"
   ],
   "id": "5f5d05e5d49fa948",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請判斷輸入句子中是否存在語法錯誤。\n",
      "\n",
      "如果存在錯誤，標註錯誤類型並給出修正後文字（錯誤類型包括：缺字漏字、錯別字錯誤、缺少標點、錯用標點、主語不明、謂語殘缺、賓語殘缺、其他成分殘缺、主語多餘、虛詞多餘、其他成分多餘、動賓搭配不當、語序不當、其他搭配不當）；如果不存在錯誤，直接標註爲「無錯誤」。\n",
      "\n",
      "輸出格式爲「標註結果：<標註結果>\\n修正後文字（如果有錯誤）：<修正後文字>」。\n",
      "\n",
      "樣例1：輸入「昨天，來賓到我校參觀，老師讓我當小導遊，我感到十分緊張。」，輸出「標註結果：無錯誤\"」。\n",
      "\n",
      "樣例2：輸入「她把一張有一個正方形的紙放進打印機裏，打印機開始印刷了，然後，「唔」一聲打印機印出來了。」，輸出「標註結果：虛詞多餘、主詞不明\\n修正後文字：她把一張正方形的紙放進打印機裏，打印機開始印刷了，然後，打印機「唔」得一聲，紙被印出來了。」\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T18:37:26.490844Z",
     "start_time": "2025-01-15T18:37:26.276591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import get_data, read_json, save_json\n",
    "import opencc\n",
    "sents = read_json(get_data('datas/archives/lijiang_sents_20250115.json'))\n",
    "new_sents = []\n",
    "converter = opencc.OpenCC('s2t.json')\n",
    "for i in sents:\n",
    "    if i['count'] > 400:\n",
    "        break\n",
    "    input = i['tc_sent']\n",
    "    # 改成繁体\n",
    "    i['revised_sent'] = converter.convert(i['revised_sent'])\n",
    "    # 无错误\n",
    "    if i['fine_grained_error_type'] == ['无错误']:\n",
    "        output = '標註結果：無錯誤'\n",
    "    else:\n",
    "        error_type = '、'.join(converter.convert(j) for j in i['fine_grained_error_type'])\n",
    "        output = f'標註結果：{error_type}\\n修正後文字：{i[\"revised_sent\"]}'\n",
    "    item = {\n",
    "        'instruction': instruction,\n",
    "        'input': input,\n",
    "        'output': output,\n",
    "    }\n",
    "    new_sents.append(item)\n",
    "    \n",
    "save_json(new_sents, get_data('datas/archives/lijiang_train_20250116.json'))\n",
    "    \n",
    "    # new_i['revised_sent'] = converter.convert(new_i['revised_sent'])\n",
    "    # new_error_type = []\n",
    "    # for j in new_i['fine_grained_error_type']:\n",
    "    #     new_error_type.append(converter.convert(j))\n",
    "    # new_i['fine_grained_error_type'] = new_error_type\n",
    "    # i.pop('remark')\n",
    "    # i.pop('sc_sent')\n",
    "    # i.pop('fine_grained_error_type')\n",
    "    # if i['fine_grained_error_type'] == ['无错误']:\n",
    "    #     i['revised_sent'] = ''\n",
    "    # new_sents.append(new_i)\n",
    "    # print(i)\n",
    "    # break\n",
    "\n",
    "# # 分割数据\n",
    "# train_split = int(0.8 * len(new_sents))  # 80% 作为训练集\n",
    "# dev_split = int(0.9 * len(new_sents))    # 10% 作为开发集，10% 作为测试集\n",
    "# \n",
    "# train_data = new_sents[:train_split]\n",
    "# dev_data = new_sents[train_split:dev_split]\n",
    "# test_data = new_sents[dev_split:]\n",
    "# \n",
    "# # 保存数据\n",
    "# save_json(train_data, get_data('exp/train.json'))\n",
    "# save_json(dev_data, get_data('datas/exp/val.json'))\n",
    "# save_json(test_data, get_data('exp/test.json'))\n",
    "# \n",
    "# print(f\"数据分割完成：train={len(train_data)}, dev={len(dev_data)}, test={len(test_data)}\")"
   ],
   "id": "b2c7f82a848cde8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sshfs/lingbao/ecnu_essay/datas/lijiang_train_20250116.json saved with 400 samples!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:21:02.070837Z",
     "start_time": "2025-01-15T13:21:01.819722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import get_data, read_json, save_json\n",
    "import json\n",
    "sents = read_json(get_data('datas/archives/lijiang_sents_20250115.json'))\n",
    "item = sents[0]\n",
    "output = {\n",
    "    'input': item['tc_sent'],\n",
    "    'output': f'标注类型：{\"、\".join(item[\"fine_grained_error_type\"])}，修正后文本：{item[\"revised_sent\"]}'\n",
    "}\n",
    "save_json(output, get_data('temp/output.json'))"
   ],
   "id": "dc3069b006053067",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sshfs/lingbao/ecnu_essay/datas/temp/output.json saved with 2 samples!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T12:30:20.986978Z",
     "start_time": "2025-01-15T12:30:20.973727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "[\n",
    "  {\n",
    "    \"instruction\": \"\",\n",
    "    \"input\": \"我們可以在這裏練習不同的樂器，爲音樂考試做準備。\",\n",
    "    \"output\": \"{\\\"label\\\": \\\"\\\"}\",\n",
    "    \"system\": \"\"\n",
    "  }\n",
    "]"
   ],
   "id": "cce9a1c06f4774bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sent_id', 1485), ('essay_id', 34), ('grade', 6), ('sent', '他点点头，然后就继续安静阅读。'), ('new_field', '新插入的字段'), ('sc_sent', '他点点头，然后就继续安静阅读。'), ('fine_grained_error_type', ['无错误']), ('revised_sent', '他点点头，然后就继续安静阅读。'), ('remark', ''), ('count', 451)])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:57:58.786115Z",
     "start_time": "2025-01-18T07:57:57.733593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "from volcenginesdkarkruntime import Ark #豆包的下载的包\n",
    "\n",
    "def doubao1(input_content: str = None):\n",
    "    client = Ark(\n",
    "        base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    )\n",
    "\n",
    "    # Non-streaming:\n",
    "    print(\"----- standard request -----\")\n",
    "    # print(type(input_content))\n",
    "    #这里插入prompt\n",
    "    prompt = f\"\"\"请专注剖析以下句子，精准判别其中是否存在如下语法错误类别：\n",
    "        缺字漏字、错别字错误、缺少标点、错用标点、主语不明、谓语残缺、宾语残缺、\n",
    "        其他成分残缺、主语多余、虚词多余、其他成分多余、语序不当、动宾搭配不当、\n",
    "        其他搭配不当或无错误。待分析句子为：{input_content}。若存在错误，\n",
    "        以最小化修正原则给出改正后的句子，并采用 JSON 格式返回错误类别；\n",
    "        若无错误，则径直返回\"无错误\"。输出需简洁明晰，无冗余表述。示例如下：\n",
    "        输入：我过了一会儿，我完成了测试。\n",
    "        输出：'{\"错误类型\":\"主语多余\",\"纠正句子\":\"过了一会儿，我完成了测试。\"}'\n",
    "        输入：有人认为富足的物质条件有利于孩子成长。\n",
    "        输出：'{\"错误类型\":\"无错误\",\"纠正句子\":\"\"}'\"\"\"\n",
    "    \n",
    "    # base_prompt = \"请专注剖析以下句子，精准判别其中是否存在如下语法错误类别：\"\n",
    "    # error_categories = \"缺字漏字、错别字错误、缺少标点、错用标点、主语不明、谓语残缺、宾语残缺、其他成分残缺、主语多余、虚词多余、其他成分多余、语序不当、动宾搭配不当、其他搭配不当或无错误。\"\n",
    "    # instruction = \"若存在错误，以最小化修正原则给出改正后的句子，并采用 JSON 格式返回错误类别；若无错误，则径直返回“无错误”。请注意，这里的都是繁体作文，修改句子需要以香港的地区习俗文化出发，在繁体中文中，单引号通常使用「」，双引号使用『』。繁体语境当中，语言的使用也存在简繁混杂的情况，不要刻意将输入的句子当中的简体字转为繁体输出。输出需简洁明晰，无冗余表述。示例如下：\"\n",
    "    # example1 = \"输入：我过了一会儿，我完成了测试。输出：{'错误类型': '主语多余', '纠正句子': '过了一会儿，我完成了测试。'}\"\n",
    "    # example2 = \"输入：有人认为富足的物质条件有利于孩子成长。输出：{'错误类型': '无错误', '纠正句子': ''}\"\n",
    "    # prompt = base_prompt + error_categories + \"待分析句子为：\" + input_content + \".\" + instruction + example1 + example2\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"ep-20241204225255-dp9xk\",#指定模型的类型\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"你是香港的高级语文老师\"},\n",
    "            {\"role\": \"user\", \"content\": prompt },#添加prompt\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "result = doubao1(\"今天天气真好，我和朋友一起出去玩\")\n",
    "\n"
   ],
   "id": "6e266922a41516ad",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "you need to support api_key or ak&sk",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 41\u001B[0m\n\u001B[1;32m     31\u001B[0m     completion \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m     32\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mep-20241204225255-dp9xk\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;66;03m#指定模型的类型\u001B[39;00m\n\u001B[1;32m     33\u001B[0m         \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m         ],\n\u001B[1;32m     38\u001B[0m     )\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n\u001B[0;32m---> 41\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mdoubao1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m今天天气真好，我和朋友一起出去玩\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m, in \u001B[0;36mdoubao1\u001B[0;34m(input_content)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdoubao1\u001B[39m(input_content: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m----> 6\u001B[0m     client \u001B[38;5;241m=\u001B[39m \u001B[43mArk\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://ark.cn-beijing.volces.com/api/v3\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Non-streaming:\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m----- standard request -----\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/essay/lib/python3.8/site-packages/volcenginesdkarkruntime/_client.py:86\u001B[0m, in \u001B[0;36mArk.__init__\u001B[0;34m(self, base_url, ak, sk, api_key, region, timeout, max_retries, http_client)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m api_key\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregion \u001B[38;5;241m=\u001B[39m region\n\u001B[0;32m---> 86\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m (ak \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m sk \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou need to support api_key or ak&sk\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     89\u001B[0m     base_url\u001B[38;5;241m=\u001B[39mbase_url,\n\u001B[1;32m     90\u001B[0m     max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     93\u001B[0m     custom_query\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     94\u001B[0m )\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_default_stream_cls \u001B[38;5;241m=\u001B[39m Stream\n",
      "\u001B[0;31mAssertionError\u001B[0m: you need to support api_key or ak&sk"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T08:20:39.236427Z",
     "start_time": "2025-01-18T08:20:22.864385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from volcenginesdkarkruntime import Ark\n",
    "import os\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = \"b5525ba2-f120-4d87-8285-5a1f9342a0c1\"\n",
    "\n",
    "client = Ark(\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    ")\n",
    "\n",
    "# Non-streaming:\n",
    "print(\"----- standard request -----\")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ep-20250118161334-zzc6d\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是豆包，是由字节跳动开发的 AI 人工智能助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"常见的十字花科植物有哪些？\"},\n",
    "    ],\n",
    "    extra_headers={'x-is-encrypted': 'true'},\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ],
   "id": "2d1ed56346837903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- standard request -----\n",
      "十字花科植物种类繁多，以下是一些常见的十字花科植物：\n",
      "### 蔬菜类\n",
      "1. **白菜**：包括大白菜和小白菜。大白菜叶片宽大，层层包裹成球状体，是北方冬季常见的蔬菜；小白菜植株相对较小，叶片较薄，口感鲜嫩，在南方广泛种植 ，四季都能吃到。\n",
      "2. **萝卜**：品种多样，有白萝卜、胡萝卜、青萝卜等。萝卜的根部肥大，可食用，营养丰富，含有多种维生素和矿物质，既可以生食、凉拌、炒菜，还能腌制。 \n",
      "3. **甘蓝**：如结球甘蓝（圆白菜、包菜）、紫甘蓝、羽衣甘蓝等。结球甘蓝叶球紧实，是常见的蔬菜；紫甘蓝叶片紫红色，富含花青素；羽衣甘蓝叶色鲜艳，形状优美，观赏价值高，同时也可食用。 \n",
      "4. **芥菜**：常见的有叶用芥菜（雪里蕻）、茎用芥菜（榨菜）、根用芥菜（大头菜）等。雪里蕻常用来腌制咸菜；榨菜的茎经腌制加工后成为人们喜爱的佐餐小菜；大头菜的肉质根可腌制或酱渍。\n",
      "5. **花椰菜**：也称花菜，花球洁白、质地致密，营养丰富，是深受人们喜爱的蔬菜。西兰花也属于花椰菜的一种，其花球呈绿色，营养较为全面，尤其是维生素 C 和胡萝卜素含量较高。 \n",
      "\n",
      "### 观赏类\n",
      "1. **紫罗兰**：二年生或多年生草本花卉，花朵色彩丰富，有紫色、紫红色、白色等，花香浓郁，常被种植于花坛、花境，也可盆栽观赏。 \n",
      "2. **诸葛菜**： 别名二月兰，为一、二年生草本植物。花朵多为蓝紫色或淡红色，常见于公园、校园等地，常自然式群植，形成美丽的景观。 \n",
      "3. **桂竹香**：多年生草本，花色有橙黄、黄褐色等，花香浓郁，花期较早，是春季园林中常见的观赏花卉。 \n",
      "\n",
      "### 药用类\n",
      "1. **菘蓝**：二年生草本，其根（板蓝根）和叶（大青叶）均可入药，有清热解毒、凉血利咽等功效，是常见的中药材。 \n",
      "2. **独行菜**：一年或二年生草本，种子可入药，有止咳平喘、祛痰等作用。  \n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
